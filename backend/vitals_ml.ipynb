{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d49171e-c008-415d-ac61-786de2b99731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading: ~/Downloads/human_vital_signs_dataset_2024.csv...\n",
      "âœ… Raw Data Loaded. Shape: (200020, 17)\n",
      "   Columns found: ['Patient ID', 'Heart Rate', 'Respiratory Rate', 'Timestamp', 'Body Temperature', 'Oxygen Saturation', 'Systolic Blood Pressure', 'Diastolic Blood Pressure', 'Age', 'Gender', 'Weight (kg)', 'Height (m)', 'Derived_HRV', 'Derived_Pulse_Pressure', 'Derived_BMI', 'Derived_MAP', 'Risk Category']\n",
      "âš™ï¸ Engineering Features (BMI, MAP)...\n",
      "âœ… Data Ready for Training. Final Shape: (200020, 19)\n",
      "ğŸŒ² Training Random Forest Classifier...\n",
      "ğŸ§  Training Neural Network on 94905 healthy samples...\n",
      "\n",
      "ğŸ‰ SUCCESS! Models Saved: 'risk_classifier.pkl', 'scaler.pkl', 'recovery_brain.pth'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. ROBUST DATA LOADING & CLEANING ---\n",
    "file_path = r\"~/Downloads/human_vital_signs_dataset_2024.csv\"\n",
    "\n",
    "print(f\"ğŸ“‚ Loading: {file_path}...\")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Raw Data Loaded. Shape: {df.shape}\")\n",
    "    print(f\"   Columns found: {list(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Please check the path.\")\n",
    "    raise\n",
    "\n",
    "# [CRITICAL FIX] Map the CSV column names to our Internal Standard\n",
    "# This fixes the \"KeyError\" by renaming what exists to what we need.\n",
    "column_mapping = {\n",
    "    'Systolic Blood Pressure': 'Systolic BP',\n",
    "    'Diastolic Blood Pressure': 'Diastolic BP',\n",
    "    'Weight (kg)': 'Weight',\n",
    "    'Height (m)': 'Height',\n",
    "    'Body Temperature': 'Body Temperature',\n",
    "    'Oxygen Saturation': 'Oxygen Saturation',\n",
    "    'Heart Rate': 'Heart Rate',\n",
    "    'Respiratory Rate': 'Respiratory Rate'\n",
    "}\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# [CRITICAL FIX] Force-Calculate Derived Features\n",
    "# Even if they exist, we recalculate to ensure they match our training logic.\n",
    "print(\"âš™ï¸ Engineering Features (BMI, MAP)...\")\n",
    "df['BMI'] = df['Weight'] / (df['Height']**2)\n",
    "df['MAP'] = df['Diastolic BP'] + (1/3) * (df['Systolic BP'] - df['Diastolic BP'])\n",
    "\n",
    "# Handle missing values (Drop rows with NaNs to prevent training errors)\n",
    "df = df.dropna()\n",
    "\n",
    "# [CRITICAL FIX] Ensure Target Variable Exists\n",
    "if 'Risk Category' not in df.columns:\n",
    "    print(\"âš ï¸ 'Risk Category' column missing. Generating based on clinical rules...\")\n",
    "    # 1 = High Risk, 0 = Low Risk\n",
    "    def get_risk(row):\n",
    "        if (row['Heart Rate'] > 100 or row['Oxygen Saturation'] < 94 or \n",
    "            row['Body Temperature'] > 37.8 or row['Systolic BP'] > 140):\n",
    "            return 1\n",
    "        return 0\n",
    "    df['Risk Category'] = df.apply(get_risk, axis=1)\n",
    "else:\n",
    "    # Ensure it's numeric (0/1) not string (\"High Risk\")\n",
    "    if df['Risk Category'].dtype == 'object':\n",
    "         df['Risk Category'] = df['Risk Category'].apply(lambda x: 1 if 'High' in str(x) else 0)\n",
    "\n",
    "print(f\"âœ… Data Ready for Training. Final Shape: {df.shape}\")\n",
    "\n",
    "# --- 2. TRAIN MODELS ---\n",
    "features = ['Heart Rate', 'Respiratory Rate', 'Body Temperature', 'Oxygen Saturation', \n",
    "            'Systolic BP', 'Diastolic BP', 'BMI', 'MAP']\n",
    "X = df[features]\n",
    "y = df['Risk Category']\n",
    "\n",
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Model A: Classifier (Random Forest)\n",
    "print(\"ğŸŒ² Training Random Forest Classifier...\")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_scaled, y)\n",
    "\n",
    "# Model B: Autoencoder (PyTorch)\n",
    "class RecoveryBrain(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(dim, 16), nn.ReLU(), nn.Linear(16, 8))\n",
    "        self.dec = nn.Sequential(nn.Linear(8, 16), nn.ReLU(), nn.Linear(16, dim))\n",
    "    def forward(self, x): return self.dec(self.enc(x))\n",
    "\n",
    "brain = RecoveryBrain(len(features))\n",
    "opt = torch.optim.Adam(brain.parameters(), lr=0.005)\n",
    "\n",
    "# Train on \"Healthy\" data only (Label 0)\n",
    "healthy_indices = (y == 0).values\n",
    "if sum(healthy_indices) > 0:\n",
    "    healthy_tensor = torch.FloatTensor(X_scaled[healthy_indices])\n",
    "    print(f\"ğŸ§  Training Neural Network on {len(healthy_tensor)} healthy samples...\")\n",
    "    for _ in range(300):\n",
    "        opt.zero_grad()\n",
    "        loss = nn.MSELoss()(brain(healthy_tensor), healthy_tensor)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: No 'Healthy' samples found. Training on full dataset (Suboptimal).\")\n",
    "    full_tensor = torch.FloatTensor(X_scaled)\n",
    "    for _ in range(300):\n",
    "        opt.zero_grad()\n",
    "        loss = nn.MSELoss()(brain(full_tensor), full_tensor)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "# --- 3. SAVE EVERYTHING ---\n",
    "joblib.dump(clf, 'risk_classifier.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "torch.save(brain.state_dict(), 'recovery_brain.pth')\n",
    "print(\"\\nğŸ‰ SUCCESS! Models Saved: 'risk_classifier.pkl', 'scaler.pkl', 'recovery_brain.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e5f893-1060-4d50-859b-9204d443fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.10.0-cp313-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.10.0-cp313-none-macosx_11_0_arm64.whl (79.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a13e45-c1a8-40ce-96de-c0a1d6bc1d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
